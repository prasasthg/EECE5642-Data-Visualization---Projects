{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72a7e7-d9f2-440d-9b55-0278d462b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import multiprocessing \n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from image_processing import preprocess_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48deea55-e327-458f-b265-280e6e2fa9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to your dataset folders\n",
    "folders = ['stop', 'ok', 'peace', 'peace_inverted', 'like', 'dislike']\n",
    "base_path = r'D:\\archive(1)\\hagrid-sample-30k-384p\\hagrid_30k'\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_path, 'train_val_' + folder)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        image_paths.append(img_path)\n",
    "        labels.append(folder)\n",
    "        \n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
    "\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df.head())\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69c858-498c-459e-bb66-0fc6d675faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images and store them in a new DataFrame\n",
    "# Number of processes to use\n",
    "num_processes = multiprocessing.cpu_count() - 1\n",
    "\n",
    "num_processes = os.cpu_count() - 2  # Use all available CPU cores except one\n",
    "with Pool(processes=num_processes) as pool:\n",
    "    preprocessed_images = pool.starmap(partial(preprocess_image), df.values)\n",
    "\n",
    "# Separate preprocessed images and labels\n",
    "X, y = zip(*preprocessed_images)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_t, X_test, y_t, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Split training dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_t, y_t, test_size = 0.111, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b0717-c3bd-4e74-ad27-d80a2e5b6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da2a705-2677-4654-9bb5-f4e04a351d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,      # Rotate images by up to 20 degrees\n",
    "    width_shift_range=0.2,  # Shift images horizontally by up to 20% of the width\n",
    "    height_shift_range=0.2, # Shift images vertically by up to 20% of the height\n",
    "    shear_range=0.2,        # Shear transformations\n",
    "    zoom_range=0.2,         # Zoom in by up to 20%\n",
    "    horizontal_flip=True,   # Flip images horizontally\n",
    "    fill_mode='nearest'     # Fill in missing pixels after rotation or shifting\n",
    ")\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_datagen = datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2056c-2347-44e7-8fef-3df7faf8f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNetV2 pre-trained on ImageNet\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Regularization strength\n",
    "l2_reg = 0.001\n",
    "\n",
    "# Combine the base model and custom classification head\n",
    "model = Sequential([base_model, GlobalAveragePooling2D(), \n",
    "                    Dense(512, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)), \n",
    "                    Dropout(0.5), \n",
    "                    Dense(512, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)), \n",
    "                    Dropout(0.5),\n",
    "                    Dense(512, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)), \n",
    "                    Dropout(0.5), \n",
    "                    Dense(6, activation='softmax')])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b348930-337c-48e4-af2e-1380b62c225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Define the filepath to save the model weights\n",
    "filepath = \"model3/\"\n",
    "\n",
    "# Create a ModelCheckpoint callback to save the model weights\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# Train the model using data augmentation\n",
    "history = model.fit(\n",
    "    train_datagen,\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=30,\n",
    "    validation_data=val_datagen,\n",
    "    validation_steps=len(X_val) // batch_size,\n",
    "    callbacks=[reduce_lr, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba408bce-1250-4145-b5cc-96f44e52c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "# Predict labesl for test set\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to classes\n",
    "predicted_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "# Print or visualize confusion matrix as needed\n",
    "print(confusion_matrix(y_test, predicted_classes))\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, predicted_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
